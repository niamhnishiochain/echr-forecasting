{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61901b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import glob,re, os, sys, random\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "from nltk.corpus import stopwords\n",
    "from random import shuffle\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "import xgboost as xgb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8bb366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(starts, ends, cases, violation):\n",
    "    facts = []\n",
    "    D = []\n",
    "    years = []\n",
    "    for case in cases:\n",
    "        contline = ''\n",
    "        year = 0\n",
    "        with open(case, 'r', encoding= 'utf-8') as f: # or mbcs CP1252 ISO-8859-1\n",
    "            for line in f:\n",
    "                dat = re.search('^([0-9]{1,2}\\s\\w+\\s([0-9]{4}))', line)\n",
    "                if dat != None:\n",
    "                    year = int(dat.group(2))\n",
    "                    break\n",
    "            if year>0:\n",
    "                years.append(year)\n",
    "                wr = 0\n",
    "                for line in f:\n",
    "                    if wr == 0:\n",
    "                        if re.search(starts, line) != None:\n",
    "                            wr = 1\n",
    "                    if wr == 1 and re.search(ends, line) == None:\n",
    "                        contline += line\n",
    "                        contline += '\\n'\n",
    "                    elif re.search(ends, line) != None:\n",
    "                        break\n",
    "                facts.append(contline)\n",
    "    for i in range(len(facts)):\n",
    "        D.append((facts[i], violation, years[i])) \n",
    "    return D\n",
    "\n",
    "def extract_parts(train_path, violation, part): \n",
    "    cases = glob.glob(train_path)\n",
    "\n",
    "    facts = []\n",
    "    D = []\n",
    "    years = []\n",
    "    \n",
    "    if part == 'relevant_law': #do extraction separate for relevant law\n",
    "        for case in cases:\n",
    "            year = 0\n",
    "            contline = ''\n",
    "            with open(case, 'r', encoding=\"utf-8\") as f: # or mbcs #CP1252 ISO-8859-1\n",
    "                for line in f:\n",
    "                    dat = re.search('^([0-9]{1,2}\\s\\w+\\s([0-9]{4}))', line)\n",
    "                    if dat != None:\n",
    "                        year = int(dat.group(2))\n",
    "                        break\n",
    "                if year> 0:\n",
    "                    years.append(year)\n",
    "                    wr = 0\n",
    "                    for line in f:\n",
    "                        if wr == 0:\n",
    "                            if re.search('RELEVANT', line) != None:\n",
    "                                wr = 1\n",
    "                        if wr == 1 and re.search('THE LAW', line) == None and re.search('PROCEEDINGS', line) == None:\n",
    "                            contline += line\n",
    "                            contline += '\\n'\n",
    "                        elif re.search('THE LAW', line) != None or re.search('PROCEEDINGS', line) != None:\n",
    "                            break\n",
    "                    facts.append(contline)\n",
    "        for i in range(len(facts)):\n",
    "            D.append((facts[i], violation, years[i]))\n",
    "        \n",
    "    if part == 'facts':\n",
    "        starts = 'THE FACTS'\n",
    "        ends ='THE LAW'\n",
    "        D = extract_text(starts, ends, cases, violation)\n",
    "    if part == 'circumstances':\n",
    "        starts = 'CIRCUMSTANCES'\n",
    "        ends ='RELEVANT'\n",
    "        D = extract_text(starts, ends, cases, violation)\n",
    "    if part == 'procedure':\n",
    "        starts = 'PROCEDURE'\n",
    "        ends ='THE FACTS'\n",
    "        D = extract_text(starts, ends, cases, violation)\n",
    "    if part == 'procedure+facts':\n",
    "        starts = 'PROCEDURE'\n",
    "        ends ='THE LAW'\n",
    "        D = extract_text(starts, ends, cases, violation)\n",
    "    if part == 'facts+circumstances':\n",
    "        starts = 'THE FACTS'\n",
    "        ends = 'RELEVANT'\n",
    "        D = extract_text(starts, ends, cases, violation)\n",
    "    if part == 'facts+circumstances+procedure':\n",
    "        starts = 'PROCEDURE'\n",
    "        ends = 'THE LAW'\n",
    "        D = extract_text(starts, ends, cases, violation)\n",
    "    return D\n",
    "\n",
    "def run_pipeline(part, article): #run tests\n",
    "    \n",
    "    print('Trained on *' + part + '* part of the cases')\n",
    "    \n",
    "    v = extract_parts(path+'/train/'+article+'/violation/*.txt', 'violation', part)\n",
    "    nv = extract_parts(path+'/train/'+article+'/non-violation/*.txt', 'non-violation', part)\n",
    "    #test_nv = extract_parts(path + '/test_violations/'+article+'/*.txt', 'non-violation', part)\n",
    "    test_v = extract_parts(path + '/test_violations/'+article+'/*.txt', 'violation', part)\n",
    "\n",
    "    data= v+nv+test_v\n",
    "    shuffle(data)\n",
    "\n",
    "    features = [i[0] for i in data]\n",
    "    target = [i[1] for i in data]\n",
    "    years = [i[2] for i in data]\n",
    "   \n",
    "    return features, target, years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9608a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'G:\\Geteilte Ablagen\\Now_Forecasting_Final_Project\\data'\n",
    "part_list = ['facts', 'circumstances', 'procedure', 'procedure+facts', 'facts+circumstances', 'facts+circumstances+procedure']\n",
    "articles = ['Article2', 'Article3', 'Article5', 'Article6', 'Article8', 'Article10', 'Article11', 'Article13', 'Article14']\n",
    "def return_train(type_part):\n",
    "    \n",
    "    \n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    year_list = []\n",
    "    article_list = []\n",
    "\n",
    "  #X_test_list = []\n",
    "  #y_test_list = []\n",
    "    for article in articles: \n",
    "        \n",
    "        X, y, year = run_pipeline(type_part, article) #X_test, y_test\n",
    "\n",
    "        X_list.extend(X) # then I don't need to flatten the lists\n",
    "        y_list.extend(y)\n",
    "        year_list.extend(year)\n",
    "        append_article = [article] * len(year)\n",
    "        article_list.extend(append_article)\n",
    "  \n",
    "  # some preprocess steps\n",
    "  # for weird encoding\n",
    "    X = [re.sub(\"\\xa0\", \" \", item) for item in X_list]\n",
    "    X = [re.sub(\"\\n\\w|\\n\", \"\",item) for item in X]\n",
    "    X = [re.sub(' +', ' ', item) for item in X]\n",
    "    X = [re.sub('\\.+', \".\",item) for item in X]\n",
    "    #X = [re.sub(\"\\n\", \"\", item) for item in X]\n",
    "    #y = np.array([1 if x == 'violation' else 0 for x in y_list])\n",
    "    #y = y.reshape((-1,1))\n",
    "    \n",
    "    feature_df = pd.DataFrame({'text': X, 'year': year_list, 'outcome': y_list, \n",
    "                              'article': article_list})\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d724159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on *facts+circumstances+procedure* part of the cases\n",
      "Trained on *facts+circumstances+procedure* part of the cases\n",
      "Trained on *facts+circumstances+procedure* part of the cases\n",
      "Trained on *facts+circumstances+procedure* part of the cases\n",
      "Trained on *facts+circumstances+procedure* part of the cases\n",
      "Trained on *facts+circumstances+procedure* part of the cases\n",
      "Trained on *facts+circumstances+procedure* part of the cases\n",
      "Trained on *facts+circumstances+procedure* part of the cases\n",
      "Trained on *facts+circumstances+procedure* part of the cases\n"
     ]
    }
   ],
   "source": [
    "# just extract the full text without the relevant law \n",
    "final_df = return_train(part_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f3ac497f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on *facts* part of the cases\n",
      "Trained on *facts* part of the cases\n",
      "Trained on *facts* part of the cases\n",
      "Trained on *facts* part of the cases\n",
      "Trained on *facts* part of the cases\n",
      "Trained on *facts* part of the cases\n",
      "Trained on *facts* part of the cases\n",
      "Trained on *facts* part of the cases\n",
      "Trained on *facts* part of the cases\n"
     ]
    }
   ],
   "source": [
    "fact_df = return_train(part_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6e27e1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on *circumstances* part of the cases\n",
      "Trained on *circumstances* part of the cases\n",
      "Trained on *circumstances* part of the cases\n",
      "Trained on *circumstances* part of the cases\n",
      "Trained on *circumstances* part of the cases\n",
      "Trained on *circumstances* part of the cases\n",
      "Trained on *circumstances* part of the cases\n",
      "Trained on *circumstances* part of the cases\n",
      "Trained on *circumstances* part of the cases\n"
     ]
    }
   ],
   "source": [
    "circumstances_df = return_train(part_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d45ed4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on *procedure* part of the cases\n",
      "Trained on *procedure* part of the cases\n",
      "Trained on *procedure* part of the cases\n",
      "Trained on *procedure* part of the cases\n",
      "Trained on *procedure* part of the cases\n",
      "Trained on *procedure* part of the cases\n",
      "Trained on *procedure* part of the cases\n",
      "Trained on *procedure* part of the cases\n",
      "Trained on *procedure* part of the cases\n"
     ]
    }
   ],
   "source": [
    "procedure_df = return_train(part_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25a18e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'G:\\Geteilte Ablagen\\Now_Forecasting_Final_Project\\data')\n",
    "final_df.to_csv('complete_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dc801784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all the other df's -> stupid memory errors\n",
    "fact_df.to_csv('fact_df.csv', index = False)\n",
    "procedure_df.to_csv('procedure_df.csv', index = False)\n",
    "circumstances_df.to_csv('circumstances_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4812a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint -> load saved csv \n",
    "os.chdir(r'G:\\Geteilte Ablagen\\Now_Forecasting_Final_Project\\data')\n",
    "final_df = pd.read_csv('complete_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eae52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for classification \n",
    "def data_prepper(df):\n",
    "    \n",
    "    target = 'outcome'\n",
    "    X = df.drop(target, axis = 1)\n",
    "    y = df[target]\n",
    "    y = y.apply(lambda x: 1 if x == 'violation' else 0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8148440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_prepper(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb642963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66223f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f355e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare text data \n",
    "model = xgb.XGBClassifier(n_estimators = 1000)\n",
    "vec = ('wordvec', TfidfVectorizer(analyzer = 'word', ngram_range = (3,4), binary = False, lowercase = True, min_df = 2, norm = 'l2', stop_words = None, use_idf = True))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "            ('features', FeatureUnion([vec],)),\n",
    "            #(\"densifier\", DenseTransformer()),\n",
    "            ('classifier', model)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b20cd400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:31:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('wordvec',\n",
       "                                                 TfidfVectorizer(min_df=2,\n",
       "                                                                 ngram_range=(3,\n",
       "                                                                              4)))])),\n",
       "                ('classifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, enable_categorical=False,\n",
       "                               gamma=0, gpu_id=-1, importance_type=None,\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=1000,\n",
       "                               n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "                               random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=1, subsample=1,\n",
       "                               tree_method='exact', validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_res['text'], y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd40a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = pipeline.predict(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "edb709ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "classrep_final = classification_report(y_test, y_hat)\n",
    "acc_final = accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "04262312",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_final = [classrep_final, acc_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d8d29be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to pickle this because otherwise I'm running into memory error's\n",
    "pickle.dump(rs_final, open(\"result_final.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d064b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_point as otherwise memory error\n",
    "fact_df = pd.read_csv('fact_df.csv')\n",
    "circumstances_df = pd.read_csv('circumstances_df.csv')\n",
    "procedure_df = pd.read_csv('procedure_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "336ab208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:31:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:47:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:57:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# loop over all the other parts\n",
    "acc_list = []\n",
    "classrep_list = []\n",
    "for data in [fact_df, circumstances_df, procedure_df]:\n",
    "    data.dropna(inplace = True)\n",
    "    X_train, X_test, y_train, y_test = data_prepper(data)\n",
    "    X_res, y_res = rus.fit_resample(X_train, y_train)\n",
    "    pipeline.fit(X_res['text'], y_res)\n",
    "    y_hat = pipeline.predict(X_test['text'])\n",
    "    classrep_list.append(classification_report(y_test, y_hat))\n",
    "    acc_list.append(accuracy_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "841bf4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.75      0.43       318\n",
      "           1       0.95      0.72      0.82      1981\n",
      "\n",
      "    accuracy                           0.73      2299\n",
      "   macro avg       0.62      0.73      0.62      2299\n",
      "weighted avg       0.86      0.73      0.77      2299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classrep_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cde8b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_other = [classrep_list, acc_list]\n",
    "pickle.dump(rs_other, open(\"result_other.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880fceff",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927c93d0",
   "metadata": {},
   "source": [
    "Now we will use historic values up a certain time point to predict the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ed7a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we didn't do that before, but no error... \n",
    "final_df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4d65e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = final_df[final_df.year <= 2011]\n",
    "test_df = final_df[final_df.year > 2011]\n",
    "# results in 75/25 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c2c6d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepper(df):\n",
    "    \n",
    "    target = 'outcome'\n",
    "    X = df.drop(target, axis = 1)\n",
    "    y = df[target]\n",
    "    y = y.apply(lambda x: 1 if x == 'violation' else 0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "89f1baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data_prepper(train_df)\n",
    "X_test, y_test = data_prepper(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b97d1ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('wordvec',\n",
       "                                                 TfidfVectorizer(min_df=2,\n",
       "                                                                 ngram_range=(3,\n",
       "                                                                              4)))])),\n",
       "                ('classifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, enable_categorical=False,\n",
       "                               gamma=0, gpu_id=-1, importance_type=None,\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=1000,\n",
       "                               n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "                               random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=1, subsample=1,\n",
       "                               tree_method='exact', validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res, y_res = rus.fit_resample(X_train, y_train)\n",
    "pipeline.fit(X_res['text'], y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d561aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = pipeline.predict(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4c2fddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_classrep_final = classification_report(y_test, y_hat)\n",
    "t_acc_final = accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8d6900a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.67      0.39       569\n",
      "           1       0.88      0.60      0.71      2429\n",
      "\n",
      "    accuracy                           0.61      2998\n",
      "   macro avg       0.58      0.63      0.55      2998\n",
      "weighted avg       0.77      0.61      0.65      2998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(t_classrep_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "43ed8605",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_final = [t_classrep_final, t_acc_final]\n",
    "pickle.dump(ts_final, open(\"time_result_final.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9c1f4e",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60efce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes way too long as one fit is already 20 + minutes and we don't have the computing time atm "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
